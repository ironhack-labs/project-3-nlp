{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8db4ac98-7502-4dec-83a0-b497340a54a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Accuracy: 0.5031825795644891\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.12      0.20      1504\n",
      "           1       0.50      0.89      0.64      1481\n",
      "\n",
      "    accuracy                           0.50      2985\n",
      "   macro avg       0.51      0.51      0.42      2985\n",
      "weighted avg       0.52      0.50      0.42      2985\n",
      "\n",
      "                                                Text  Predicted_Label\n",
      "0  Yo no creo que a nadie le haya encantado un pe...                1\n",
      "1  No va a resolver sus problemas de crédito o me...                1\n",
      "2                                Te encantará este !                1\n",
      "3  Yo estaba a volar a un aeropuerto varias horas...                1\n",
      "4  ( Maid En Manhattan , The Wedding Planner , Je...                1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import joblib\n",
    "import gc\n",
    "\n",
    "# Define file paths for Jupyter Notebook\n",
    "train_file_path = r\"C:/Users/harid/Downloads/TRAINING_DATA.txt\"\n",
    "real_file_path = r\"C:/Users/harid/Downloads/REAL_DATA.txt\"\n",
    "\n",
    "# Load training data\n",
    "train_data = pd.read_csv(train_file_path, sep=\"\\t\", header=None, names=[\"Label\", \"Text\"], encoding=\"utf-8\")\n",
    "\n",
    "# Read and clean REAL_DATA.txt\n",
    "with open(real_file_path, \"r\", encoding=\"utf-8\", errors=\"replace\") as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "# Cleaning any irregularities\n",
    "cleaned_lines = [line.strip() for line in lines if line.strip()]\n",
    "\n",
    "# Ensure we only take valid rows\n",
    "real_texts = []\n",
    "for line in cleaned_lines:\n",
    "    parts = line.split(\"\\t\", 1)  # Ensure we split only on the first tab\n",
    "    if len(parts) == 1:\n",
    "        real_texts.append(parts[0])  # If there's no tab, assume it's text\n",
    "    else:\n",
    "        real_texts.append(parts[1])  # Take only the text part\n",
    "\n",
    "# Create DataFrame\n",
    "real_data = pd.DataFrame({\"Text\": real_texts})\n",
    "\n",
    "# Convert labels to integers\n",
    "train_data[\"Label\"] = train_data[\"Label\"].astype(int)\n",
    "\n",
    "# Text preprocessing function\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(f\"[{string.punctuation}]\", \"\", text)\n",
    "    text = re.sub(r\"\\d+\", \"\", text)\n",
    "    return text\n",
    "\n",
    "# Apply preprocessing\n",
    "train_data[\"Cleaned_Text\"] = train_data[\"Text\"].apply(preprocess_text)\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    train_data[\"Cleaned_Text\"], train_data[\"Label\"], test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Convert text to numerical features using TF-IDF with optimized parameters\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,3), stop_words=\"english\", max_features=30000)\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "# Free up memory\n",
    "gc.collect()\n",
    "\n",
    "# Define XGBoost parameters and enable GPU acceleration\n",
    "param_grid = {\n",
    "    'n_estimators': [300],\n",
    "    'learning_rate': [0.1],\n",
    "    'max_depth': [7],\n",
    "    'tree_method': ['hist'],\n",
    "    'device': ['cuda']\n",
    "}\n",
    "\n",
    "# Use StratifiedKFold for better cross-validation\n",
    "stratified_kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform GridSearchCV to optimize hyperparameters\n",
    "grid_search = GridSearchCV(XGBClassifier(), param_grid, cv=stratified_kfold, scoring=\"accuracy\", n_jobs=-1, verbose=2)\n",
    "grid_search.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Train the best model\n",
    "classifier = grid_search.best_estimator_\n",
    "classifier.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Evaluate model\n",
    "predictions = classifier.predict(X_test_tfidf)\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(classification_report(y_test, predictions))\n",
    "\n",
    "# Function to classify new sentences\n",
    "def classify_sentences(sentences):\n",
    "    sentences = [preprocess_text(sentence) for sentence in sentences]\n",
    "    sentences_tfidf = vectorizer.transform(sentences)\n",
    "    return classifier.predict(sentences_tfidf)\n",
    "\n",
    "# Classify real dataset\n",
    "real_data[\"Predicted_Label\"] = classify_sentences(real_data[\"Text\"])\n",
    "print(real_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8391e96c-71ba-40e5-88e9-b2d9f3a9ec49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
