{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7c8045c-8930-44ee-b117-2b68b5b5f02a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\jesus\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\jesus\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "\n",
    "# Download NLTK resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "840d0b81-5165-4f4d-9a10-42f9a050740a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Combined Dataset Preview:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2\\tYo no creo que a nadie le haya encantado un...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2\\tNo va a resolver sus problemas de crÃ©dito ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2\\tTe encantarÃ¡ este !</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2\\tMi padre llegÃ³ con la primera ola de fuerz...</td>\n",
       "      <td>6 de junio 1944 .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2\\tY podemos todos estar de acuerdo que los en...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text               label\n",
       "0  2\\tYo no creo que a nadie le haya encantado un...                 NaN\n",
       "1  2\\tNo va a resolver sus problemas de crÃ©dito ...                 NaN\n",
       "2                            2\\tTe encantarÃ¡ este !                 NaN\n",
       "3  2\\tMi padre llegÃ³ con la primera ola de fuerz...   6 de junio 1944 .\n",
       "4  2\\tY podemos todos estar de acuerdo que los en...                 NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load datasets\n",
    "data_train = pd.read_csv(\"C:\\\\Users\\\\jesus\\\\project-3-nlp\\\\TRAINING_DATA.txt\", \n",
    "                         encoding='latin-1', header=None, names=['text', 'label'], on_bad_lines='skip')\n",
    "data_val = pd.read_csv(\"C:\\\\Users\\\\jesus\\\\project-3-nlp\\\\REAL_DATA.txt\", \n",
    "                       encoding='latin-1', header=None, names=['text', 'label'], on_bad_lines='skip')\n",
    "\n",
    "# Reduce the training set for faster testing\n",
    "data_train = data_train.head(1000)\n",
    "\n",
    "# Combine datasets\n",
    "data = pd.concat([data_val, data_train], ignore_index=True)\n",
    "\n",
    "# Preview combined dataset\n",
    "print(\"\\nCombined Dataset Preview:\")\n",
    "display(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49b41ace-7f8b-40c6-8713-364ac0008670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean HTML content\n",
    "def clean_html(text):\n",
    "    text = re.sub(r'<script.*?>.*?</script>', '', text, flags=re.DOTALL)\n",
    "    text = re.sub(r'<style.*?>.*?</style>', '', text, flags=re.DOTALL)\n",
    "    text = re.sub(r'<!--.*?-->', '', text, flags=re.DOTALL)\n",
    "    return BeautifulSoup(text, \"html.parser\").get_text()\n",
    "\n",
    "# Function to preprocess text\n",
    "def preprocess_text(text):\n",
    "    text = clean_html(text)\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)  # Remove special characters and numbers\n",
    "    text = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', text)  # Remove single characters\n",
    "    text = re.sub(r'^\\s*[a-zA-Z]\\s+', '', text)  # Remove single characters at the start\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Replace multiple spaces with a single space\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    words = word_tokenize(text)\n",
    "    stop_words = set(stopwords.words(\"spanish\"))\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    stemmer = SnowballStemmer('spanish')\n",
    "    words = [stemmer.stem(word) for word in words]\n",
    "    return \" \".join(words)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00bd40cb-50c6-484b-9bf1-50a9e4f3bdfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preprocessed Dataset Preview:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>preprocessed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2\\tYo no creo que a nadie le haya encantado un...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cre nadi encant pen flcid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2\\tNo va a resolver sus problemas de crÃ©dito ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>va resolv problem crdit mejor relacin padr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2\\tTe encantarÃ¡ este !</td>\n",
       "      <td>NaN</td>\n",
       "      <td>encant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2\\tMi padre llegÃ³ con la primera ola de fuerz...</td>\n",
       "      <td>6 de junio 1944 .</td>\n",
       "      <td>padr lleg primer ola fuerz ali da</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2\\tY podemos todos estar de acuerdo que los en...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pod acuerd envas mient</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text               label  \\\n",
       "0  2\\tYo no creo que a nadie le haya encantado un...                 NaN   \n",
       "1  2\\tNo va a resolver sus problemas de crÃ©dito ...                 NaN   \n",
       "2                            2\\tTe encantarÃ¡ este !                 NaN   \n",
       "3  2\\tMi padre llegÃ³ con la primera ola de fuerz...   6 de junio 1944 .   \n",
       "4  2\\tY podemos todos estar de acuerdo que los en...                 NaN   \n",
       "\n",
       "                            preprocessed_text  \n",
       "0                   cre nadi encant pen flcid  \n",
       "1  va resolv problem crdit mejor relacin padr  \n",
       "2                                      encant  \n",
       "3           padr lleg primer ola fuerz ali da  \n",
       "4                      pod acuerd envas mient  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Handle missing values in the 'text' column\n",
    "data['text'] = data['text'].fillna('').astype(str)\n",
    "\n",
    "# Apply preprocessing\n",
    "data['preprocessed_text'] = data['text'].apply(preprocess_text)\n",
    "\n",
    "# Preview preprocessed data\n",
    "print(\"\\nPreprocessed Dataset Preview:\")\n",
    "display(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8907be68-549f-424a-98e0-d91b82ff7998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (605, 3)\n",
      "Validation data shape: (137, 3)\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset\n",
    "data_train, data_val = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Drop rows with missing labels\n",
    "data_train = data_train.dropna(subset=['label'])\n",
    "data_val = data_val.dropna(subset=['label'])\n",
    "\n",
    "# Ensure labels are strings\n",
    "data_train['label'] = data_train['label'].astype(str)\n",
    "data_val['label'] = data_val['label'].astype(str)\n",
    "\n",
    "# Check the shape of the datasets\n",
    "print(f\"Training data shape: {data_train.shape}\")\n",
    "print(f\"Validation data shape: {data_val.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "381b5501-8191-41ba-a9d0-79b06fee43a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training features shape: (605, 1663)\n",
      "Validation features shape: (137, 1663)\n"
     ]
    }
   ],
   "source": [
    "# Initialize TF-IDF Vectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Fit-transform the training set and transform the validation set\n",
    "X_train_tfidf = vectorizer.fit_transform(data_train['preprocessed_text'])\n",
    "X_val_tfidf = vectorizer.transform(data_val['preprocessed_text'])\n",
    "\n",
    "# Check the shape of the feature matrices\n",
    "print(f\"Training features shape: {X_train_tfidf.shape}\")\n",
    "print(f\"Validation features shape: {X_val_tfidf.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f4742452-a695-4ed8-a916-c7fd02b53db0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.00\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train the Naive Bayes classifier\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train_tfidf, data_train['label'])\n",
    "\n",
    "# Predict on the validation set\n",
    "y_pred = clf.predict(X_val_tfidf)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(data_val['label'], y_pred)\n",
    "print(f\"Validation Accuracy: {accuracy:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
